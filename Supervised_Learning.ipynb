{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is supposed to be an introduction to machine learning models for supervised problems in machine learning. The purpose of the notebook is to give, firstly, an introduction to the supervised learning methods, the terminology and the key points when approaching a machine learning problem, and it should be also a mental guide to approach a large number of machine learning problems. \n",
    "\n",
    "We will try to give a balanced amount of theory for understand the theory underlying the model we will present, combined with practical examples, implement the models in Python language and mostly using the scikit-learn library. \n",
    "\n",
    "The structure of the contents follows the general flow chart that a machine learning problem should follow: after giving a general introduction, we provide the basic ingredients of probability and statistics containing the general goal addressed by a learning algorithm. This part, in general, gives the tools necessary to the __exploration of data__ part in the problem. \n",
    "After this we list the models we want to study with the hyperlink to the corresponding notebook. This part encapsule the __modelization__ part. \n",
    "In the last part we concentrate on the __validation__ tools of the models, and to the __intepretability__ issues. \n",
    "\n",
    "\n",
    "\n",
    "The main references I used for the lessons are the following:\n",
    "\n",
    "* _\"The Elements of Statistical Learning\"_, T. Hastie, R. Tibshirami, J. Friedman\n",
    "* _\"Statistics and Machine Learning in Python\"_, E.Duchesnay, T.Löfstedt, F.Younes\n",
    "* _\"Introduction to Machine Learning\"_, Master Course of École Normale Supérieure - Paris (ENS)\n",
    "* _https://scikit-learn.org/_\n",
    "* _https://christophm.github.io/interpretable-ml-book/_\n",
    "* _https://www.wikipedia.org_\n",
    "* _https://towardsdatascience.com_\n",
    "* _https://www.kaggle.com_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Introduction](#s1)\n",
    "\n",
    "\n",
    "### [Statistical Tools for Learning](#s2)\n",
    "- [Statistics I: Basics](#s2.1)\n",
    "- [Statistics II: Univariate/MultiVariate Statistic, Correlations](#s2.2)\n",
    "- [Statistic III: Learning Algorithms](#s2.3)\n",
    "\n",
    "\n",
    "\n",
    "### [Modelization](#s3)\n",
    "- [Models for Regression](#s3.1)\n",
    "- [Models for Classification](#s3.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### [Model Evaluation, Selection and Assessment](#s4)\n",
    "- [Model Evaluation](#s4.1)\n",
    "    - [Regression Metrics](#s4.1.1)\n",
    "    - [Classification Metrics](#s4.1.2)\n",
    "    \n",
    "\n",
    "- [Model Selection and Assessment](#s4.2)\n",
    "    - [Bias-Variance Tradeoff](#s4.2.1)\n",
    "    - [Cross Validation](#s4.2.2)\n",
    "    - [Other Issues](#s4.2.3)\n",
    "    \n",
    "\n",
    "### [Interpretability](#s5)\n",
    "- [Permutation Importance](#s5.1)\n",
    "- [Partial Dependence Plot (PDP)](#s5.2)\n",
    "- [SHAP Values](#s5.3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id='s1'>Introduction</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning covers two main types of data analysis: **Unsupervised Learning** and **Supervised Learning**. In the former case we are dealing with problem of exploratory analysis where we have to discover strucutre and pattern within the data, while in the latter case we deal with a predective analysis problem. In all the dataset there is a set of variables that might be denoted as **input** which are measured or preset. These have come influence on one or more **output**. When the goal is to use the inputs to predict the values of the outputs we talk about supervised learning, that is the type of data analysis we want to focus on here. \n",
    "Once we made a very first split between the two main tasks machine learning address to, and we decide to concentrate on supervised learning, another important split happend within supervised method depending of the type of variables. Before introducing this split it worth to give some terminology about the type of variables in the game. \n",
    "\n",
    "\n",
    "First of all we have used the more modern language of machine learning. In the statistical literature the inputs are often called the _predictors_, a term we will use interchangeably with inputs, and more classically the _independent variables_. In the pattern recognition literature the term _features_ is preferred, which we use as well. The outputs are called the _responses_, or classically the _dependent variables_.\n",
    "\n",
    "Both input and outputs vary in nature and they can take values in basically 3 categories: **quantitative**, **qualitative** (or **categorical**, or **discrete**), and a third type called **ordered categorical**. In the first case we have variables taking numerical continous values. In the second case the variables take values in a finite set or classe. The elements in a class can be both numerical (but finite, discrete) or simply qualitative (like red, blue, green). The last type refers to a categorical variable with a natural order (like, small, medium and large). \n",
    "\n",
    "Once we introduced the type of variables we can divide a supervised problem into towo main classes depending on the type of the output variables. If we have to predict one or more quantitative output we talk about **Regression** while if the output variables is categorical we will deal with **Classification**.\n",
    "Inputs also vary in measurement type; we can have some of each of qualitative and quantitative input variables. These have also led to distinctions in the types of methods that are used for prediction task we chose depending on output variables: some methods are defined most naturally for quantitative inputs, some most naturally for qualitative and some for both.\n",
    "\n",
    "We will typically denote the input variable dataset by a matrix $N\\times p$, $X$. We also label a $p$-vector (row) by $x_i$ with $i=1,\\cdots N$, running over all the observations. Instead, the columns $N$-vector, which in principle contains all the $N$ observation for a given features, it will be denoted by $x_j$, with $j=1,\\cdots, p$. \n",
    "The output vector will be denoted by $Y$ and the predcited values will always be labelled by $\\hat{Y}$, if the output takes values in $\\mathbb{R}$, so it's quantitative. If we are dealing with categorical output we will use the letter $G$ and the predcited value by $\\hat{G}$, taking values in the class $\\mathcal{G}$.\n",
    "\n",
    "We need data to construct prediction rules, often a lot of it. We thus suppose we have available a set of measurements $(x_i, y_i)$ or $(x_i, g_i)$, $i=1,\\cdots N$ , known as the __training dataset__, with which to construct our prediction rule. We will be provided also what we call a __test dataset__ that will be used to test our accuracy as we will see in the following. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: dashed rgb(0,1,0) 0.9px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id='s2'>Statistical Tools for Learning</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give here a brief section containing basic tools of statistics useful for the following and for understand the notation of the notebooks in the repository. In the first subsection we introduce the very basic ingredients of statistics and probability while in the second subsection we give an overview of how supervised learning algorithms work and we will call it Decision Theory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2.1'></a>\n",
    "### Statistics I: Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call a random variable $X$ (here $X$ is just a random variable regardless of the matrix structure we introduced before), whose distrution is $P(X)$. The expected value operator $E(\\cdot)$ of $X$ satisfies:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\\begin{align}\n",
    "E(X+c)&=E(X)+c\\\\\n",
    "E(X+Y)&=E(X)+E(X)\\\\\n",
    "E(\\alpha X)&=\\alpha E(X)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where $c$ is a constant, and $Y$ is another random variable. The estimator $\\bar{x}$, called the __mean__ on a sample of size $N$ is given by\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\\begin{align}\n",
    "\\bar{x}=\\frac{1}{N}\\sum_{i}x_i\n",
    "\\end{align}\n",
    "\n",
    "$\\bar{x}$ is itself a random variable with properties:\n",
    "\n",
    "- $E(\\bar{x})=\\bar{x}$\n",
    "- $\\text{Var}(\\bar{x})=\\frac{\\text{Var}(X)}{N}$\n",
    "\n",
    "The __variance__ is defined as:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}(X)=E((X-E(X))^2)=E(X^2)-(E(X))^2\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "The corresponding estimator is:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\\begin{align}\n",
    "\\sigma_x^2=\\frac{1}{N-1}\\sum_i(x_i-\\bar{x})^2\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "The __standard deviation__ is defined as:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Std}(X)=\\sqrt{\\text{Var}(X)}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "with an estimator which is simply the square root of the estimator of the variance.\n",
    "\n",
    "We define the __covariance__ as:\n",
    "\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Cov}(X,Y)=E(X-E(X))E(Y-E(Y))=E(XY)-E(X)E(Y)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "with the following properties:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Cov}(X,X)&=\\text{Var}(X)\\\\\n",
    "\\text{Cov}(X,Y)&=\\text{Cov}(Y,X)\\\\\n",
    "\\text{Cov}(cX,Y)&=c\\text{Cov}(X,Y)\\\\\n",
    "\\text{Cov}(X+c,Y)&=\\text{Cov}(X,Y)\\\\    \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "The __correlation__ is defined as:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\\begin{align}\n",
    "\\rho_{X,Y}=\\text{corr}(X,Y)=\\frac{\\text{Cov}(X,Y)}{\\text{Var}(X)\\text{Var}(Y)} \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "The analysis of the correlation and covariance takes particular importance when dealing with an high number of input variables and knowing the correlation between the variables is fundamental. There are by the way several statistical method to deal with what is called in general __multivariate statistics__ and they will be discussed in a notebook apart where we will discuss the various methods of analysing correlation between quantitative variables, qualitative variables or both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2.1'></a>\n",
    "### Statistics II: Univariate/MultiVariate Statistic, Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s2.3'></a>\n",
    "### Statistics III: Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In supervised machine learning, the goal is, given some observations $(x_i, y_i)\\in \\mathcal{X}\\times\\mathcal{Y}$ of inputs/ouptus and given a new input $x\\in\\mathcal{X}$ to predict well the next output $y\\in\\mathcal{Y}$. The training dataset will be denoted $\\mathcal{T}=\\{(x_i, y_i)\\}$ for $i = 1,\\cdots, N$. A standard assumption is that the observations $(x_i,y_i)$ are realizations of i.i.d. random variables from a joint distribution $P(x,y)$.\n",
    " \n",
    "A learning rule $\\mathcal{A}$ is a function that associates to training data $\\mathcal{T}$ a prediction function $\\hat{f}$ (the hat on f indicates that it is an estimator):\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{A}: (\\mathcal{X}\\times\\mathcal{Y})^N&\\to\\mathcal{Y}^{\\mathcal{X}}\\\\\n",
    "\\mathcal{T}&\\to\\hat{f}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "The estimated function $\\hat{f}$ is constructed to predict a new output $y$ from a new $x$, where $(x,y)$\n",
    "is a pair of test data, i.e. not observed in the training data. The function $\\hat{f}$ is an estimator because it depends on the data $\\mathcal{T}$ and not on unobserved parameter. If $\\mathcal{T}$ is random, it is a random function. \n",
    "\n",
    "The objective is to find an estimator $f\\in \\mathcal{H}$ that predicts well new data by minimizing the __risk function__:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{R}(f)=E\\left[L(f(x),y)\\right]=\\int L(f(x),y)dP(x,y)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where $L(f(x),y)$ is called __loss function__. The ultimate goal of a learning algorithm is to find a function $\\hat{f}$ among the fixed class of function $\\mathcal{H}$ for which the risk $\\mathcal{R}(\\hat{f})$ is minimal:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}=\\arg\\min_{\\mathcal{H}}\\mathcal{R}(f)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "However, the statistician cannot compute the expectation (and thus the risk) because he does not know the distribution $P(x,y)$. A common method in supervised machine learning is therefore to replace the risk\n",
    "with the __empirical risk__:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\mathcal{R}}(f)=\\frac{1}{N}\\sum_{i=1}^NL(f(x_i),y_i)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "and seek for a function:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}=\\arg\\min_{\\mathcal{H}}\\hat{\\mathcal{R}}(f)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "This princple is called __Empirical Risk Minimization (ERM)__ and is a principle in statistical learning theory which defines a family of learning optimization algorithms. In general then, the minimization problem over all the functions is ambiguos beacause there is an infinitely number of functions passing by the training points. Therefore in principle in order to obtain useful results we must restrict the eligible solutions to a smaller set of functions, namely, we must impose restrictions to $\\mathcal{H}$.\n",
    "\n",
    "These restrictions can be described as __complexity__ restrictions and take different form. One of the common way to impose restriction is by using a parametric representation. For example in the linear case we choose $\\mathcal{H}$ to be the class of linear function parametrized by a set of parameters and we minimize with respect the paramaters. This choice set the type of __model__ we use (linear is the case of linear functions). Moreover the choice of the risk function gives us different __method__ inside the same model. For example in the case of linear model we could have Ordinary Least Squared, Lasso, Ridge Linear models. We will see these models in the following sections and more in details in the dedicated notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: dashed rgb(0,1,0) 0.9px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id='s3'>Modelization</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the large number of models and method to approach a supervised regressio problem in machine learning we will be focusin mostly on the following models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s3.1'></a>\n",
    "###  Models for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Linear Models**:\n",
    "    - [Ordinary Least Squares Linear Method (OLS)](link)\n",
    "    - [Ridge Linear Method (Ridge)](link)\n",
    "    - [Lasso Linear Method (Lasso)](link)\n",
    "    \n",
    "\n",
    "- [**Decision Trees**](link)\n",
    "\n",
    "\n",
    "- **Ensemble methods**:\n",
    "    - [Random Forest](link)\n",
    "    - [Gradient Boosting](link)\n",
    "\n",
    "\n",
    "- **Nearest Neighbors**\n",
    "\n",
    "\n",
    "- **Support Vector Machines (SVM)**\n",
    "\n",
    "\n",
    "- **Neural Network Models**:\n",
    "    - Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s3.2'></a>\n",
    "###  Models for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Linear Models**:\n",
    "    - Logistic regression\n",
    "    \n",
    "- **Nearest Neighbors**\n",
    "\n",
    "- **Support Vector Machines (SVM)**\n",
    "\n",
    "- **Decision Trees**\n",
    "\n",
    "- **Ensemble methods**:\n",
    "    - Random Forest\n",
    "\n",
    "- **Neural Network Models**:\n",
    "    - Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: dashed rgb(0,1,0) 0.9px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a class=\"anchor\" id='s4'>Model Evaluation, Selection and Assessment</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s4.1'></a>\n",
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common practice when performing a supervised machine learning experiment to hold out part of the available data as a test set where we evaluate how our model, trained on the training set, is good at predicting output variables from a new input dataset. For this purpose we usually have two way of evaluation: method based on __errors__ and method based on __scoring__. \n",
    "\n",
    "In general, scoring methods follow the convention that higher return values are better than lower return values. On the other side, if we use method based on errors it would be better to have small values. Both of method are implementd by __metrics__ defined in very different way, depending on the problem, and computing a distance between the predicted output and the true value, known from the tes set. \n",
    "\n",
    "There are methods for regresion models and for classification models and we will give a brief list below, giving also the implementation rule in Python. Some of them they also work for multi-output problems. The `sklearn.metrics` is the scikit-learn module that implements the loss, score, and utility functions to measure regression and classification evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s4.1.1'></a>\n",
    "#### Regression Metrics\n",
    "\n",
    "We give below a list of the most common evaluation methods for regression used in machine learning. We define them theoretical and we will see the implementation in scikit-learn library. For more method we suggest to consult the page of the [scikit-learn library](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mean_absolute_error` function computes mean absolute error, a risk metric corresponding to the expected value of the absolute error loss\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "<center>\n",
    "$$\n",
    "\\text{MAE}\\,\\left(Y,\\hat{Y}\\right)=\\frac{1}{N}\\sum_{i=0}^{N-1}|y_i-\\hat{y}_i|\n",
    "$$\n",
    "</center>\n",
    "\n",
    "Here the implementation of the mean absolute error function in `sklearn`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.metrics.mean_absolute_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mean_squared_error` function computes mean square error, a risk metric corresponding to the expected value of the squared (quadratic) error or loss\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "<center>\n",
    "$$\n",
    "\\text{MSE}\\,\\left(Y,\\hat{Y}\\right)=\\frac{1}{N}\\sum_{i=0}^{N-1}(y_i-\\hat{y}_i)^2\n",
    "$$\n",
    "</center>\n",
    "\n",
    "Here the implementation of the mean squared error function in `sklearn`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.metrics.mean_squared_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average', squared=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### R² score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `r2_score` function computes the coefficient of determination, usually denoted as $R^2$.\n",
    "\n",
    "It represents the proportion of variance (of $Y$) that has been explained by the independent variables in the model. It provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model, through the proportion of explained variance.\n",
    "\n",
    "As such variance is dataset dependent, $R^2$ may not be meaningfully comparable across different datasets. Best possible score is $1.0$ and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of $y$, disregarding the input features, would get a $R^2$ score of 0.0.\n",
    "\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "<center>\n",
    "$$\n",
    "R^2\\left(Y,\\hat{Y}\\right)=1-\\frac{\\sum_{i}(y_i-\\hat{y}_i)^2}{\\sum_{i}(y_i-\\bar{y})^2}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where $\\bar{y}=\\frac{1}{N}\\sum_{i}y_i$.\n",
    "\n",
    "Here the implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.metrics.r2_score(y_true, y_pred, sample_weight=None, multioutput='uniform_average')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s4.1.2'></a>\n",
    "#### Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As in the case of regression we give list here the most used evaluation methods for classification used. We define them theoretical and we will see the implementation in scikit-learn library. For more method we suggest to consult the page of the [scikit-learn library](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes subset accuracy: it compare the prediction and the true values and it counts how many output target we predicted correctly. The implementation reads \n",
    "\n",
    "`sklearn.metrics.accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix\n",
    "\n",
    "By definition a confusion matrix $C_{i,j}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$. It's implemented by the following commmand line\n",
    "\n",
    "`sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logarithimc Loss\n",
    "\n",
    "Logarithimc Loss or Logistic Loss or cross-entropy loss is the method used in logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of the true labels given a probabilistic classifier’s predictions. The log loss is only defined for two or more labels. For a single sample with true label $y$ in $\\{0,1\\}$ and estimated probability $y_p$ that $y=1$, the log loss reads\n",
    "\n",
    "$$\n",
    "-\\log P(y|y_p)=-(y\\log(P_y)+(1-P_y)\\log(1-P_y))\n",
    "$$\n",
    "\n",
    "For more general multi-class output it reads:\n",
    "\n",
    "$$\n",
    "-\\log P(y|y_p)=-\\sum_{i,j}y_{i,j}P_{i,j}\n",
    "$$\n",
    "\n",
    "It's implement in scikit as\n",
    "\n",
    "`sklearn.metrics.log_loss(y_true, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s4.2'></a>\n",
    "### Model Selection and Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generalization performance of a learning method relates to its prediction capability on independent test data. Assessment of this performance is extremely important in practice, since it guides the choice of learning method or model, and gives us a measure of the quality of the ultimately chosen model.\n",
    "\n",
    "Let's consider the case where we have our target variable $Y$, a vectors of inputs $X$, and a predicted model $\\hat{f}(X)$, that has been estimated froma training set $\\mathcal{T}$. We also have a loss function $L(Y, \\hat{f}(X))$. \n",
    "\n",
    "We define the __test error__, also referred to as __generalizaed error__, as the prediction error over an independent and test sample $(X,Y)$ drawn randomly from their joint distribution. Here the training set $\\mathcal{T}$ is fixed, and the test error refers to this specific training set\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Err}_{\\mathcal{T}}=E\\left[L(Y, \\hat{f}(X)) | \\mathcal{T} \\right] \n",
    "\\end{align}\n",
    "\n",
    "A related quantity is the __expected test error__\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Err}=E\\left[\\text{Err}_{\\mathcal{T}}\\right] \n",
    "\\end{align}\n",
    "\n",
    "The expectation averages over everything that is random, included the randomnees in the training set that produced $\\hat{f}$.\n",
    "\n",
    "In general we talk about __training error__ when we take the average loss over the training sample\n",
    "\\begin{align}\n",
    "\\bar{\\text{err}}=\\frac{1}{N}\\sum_{i=1}^N L\\left(y_i, \\hat{f}(x_i)\\right)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "We would like to know the expected test error of our estimated model. As the model becomes more and more complex, it uses the training data more and is able to adapt to more complicated underlying structures. This can lead to the __overfitting__ issue. The opposite is also true, and when the model is 'too simple' we end up in a __underfitting__ problem. There is some intermediate model complexity that gives minimum expected test error.\n",
    "Training error consistently decreases with model complexity, typically dropping to zero if we increase the model complexity enough. However, a model with zero training error is overfit to the training data and will typically generalize poorly.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img width=400 src='images/bias2.png' /> \n",
    "</div>\n",
    "\n",
    "\n",
    "In the figure above the light curves show the training error $\\bar{\\text{err}}$ (blue) and test error $\\text{Err}_{\\mathcal{T}}$ (red), and the solid curves show the expected test error Err and $E[\\bar{\\text{err}}]$.\n",
    "\n",
    "\n",
    "\n",
    "There are various numbers of methods for estimating the expected test error for a model. Typically our model will have a tuning parameter or parameters $\\alpha$ and so we can write our predictions as $\\hat{f}_{\\alpha}(X)$. The tuning parameter varies the __complexity__ of our model, and we wish to find the value of $\\alpha$ that minimizes error, that is, produces the minimum of the average test error. It is important to note that there are in fact two separate goals that we might have in mind:\n",
    "\n",
    "- __Model Selection__ : estimating the performance of different models in order to choose the best one\n",
    "- __Model Assessment__: having chosen a final model, estimating its test error on new data\n",
    "\n",
    "\n",
    "Before going through the method of validation of the model it's important to understand how the error comes from and how we can tune it to have better performance. A fundamental issue related to this is the decomposition of the error in bias and variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s4.2.1'></a>\n",
    "#### Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first issue in the model selection is the tradeoff between __bias__ and __variance__. Imagine that we have available several different, but equally good, training data sets. A learning algorithm is biased for a particular input $X$ if, when trained on each of these data sets, it is systematically incorrect when predicting the correct output for $X$. A learning algorithm has high variance for a particular input $X$ if it predicts different output values when trained on different training sets. The test error of a learned classifier is related to the sum of the bias and the variance of the learning algorithm. Generally, there is a tradeoff between bias and variance. A learning algorithm with low bias must be \"flexible\" so that it can fit the data well. But if the learning algorithm is too flexible, it will fit each training data set differently, and hence have high variance. A key aspect of many supervised learning methods is that they are able to adjust this tradeoff between bias and variance. \n",
    "\n",
    "Going more in the mathematical aspect, we assume that the real model will be described by \n",
    "\n",
    "\\begin{align}\n",
    "Y=f(X)+\\epsilon\n",
    "\\end{align}\n",
    "where $f$ is the real model describing the data and $\\epsilon$ is the irrreducbile error with $E(\\epsilon)=0$ and $\\text{Var}(\\epsilon)=\\sigma^2$. The test error of a model fit $\\hat{f}$, using the squared-error loss will be\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Err}(X)&=E\\left[(Y-\\hat{f}(X))^2 \\right]\\\\\n",
    "&=\\sigma^2+\\left[E[\\hat{f}(X)]-f(X) \\right]^2 + E\\left[\\hat{f}(X)-E[\\hat{f}(X)] \\right]^2\\\\\n",
    "&=\\sigma^2 + \\text{Bias}^2\\left(\\hat{f}(X)\\right) + \\text{Var}\\left(\\hat{f}(X)\\right)\\\\\n",
    "&=\\text{Irreducible Error} + \\text{Bias}^2 + \\text{Variance}\n",
    "\\end{align}\n",
    "\n",
    "The first term is the variance of the target around its true mean $f(X)$, and cannot be avoided no matter how well we estimate $f$. The second term is the squared bias, the amount by which the average of our estimate differs from the true mean; the last term is the variance; the expected squared deviation of $\\hat{f}(X)$ around its mean. Typically the more complex we make the model $\\hat{f}$, the lower the bias but the higher the variance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img width=400 src='images/biasvariance.png' /> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _high bias_: usually related to high training error and it gives an idea of how your model is far from the real one. A good way to check if your model has high biased or not is to compare the training and test error and look if they are both similar and high.\n",
    "\n",
    "- _high variance_: related to high test error and it related to how your fitted model depends on the training set you chose. \n",
    "\n",
    "\n",
    "\n",
    "The purpose of the decomposition is therefore to give you some theoretical tools to tune your model in order to get a good compromise between bias and variance and hence get a minumum error. In order to do so twe need some method of validation in order to choose the model and once chosen to tune the eventual hyperparameters to reach the optimal model. One of the most used way is the __cross validation__ (__CV__)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s4.2.2'></a>\n",
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably the simplest and most widely used method for estimating prediction error is cross-validation . This method directly estimate the expected test error Err. There are different method inside cross validation and we will show the most used:\n",
    "\n",
    "- Holdout\n",
    "- $k$-Fold CV\n",
    "- Repeated $k$-Fold CV\n",
    "- Stratified  $k$-Fold CV\n",
    "- Leave-One-Out CV\n",
    "- Leave-One-Group-Out CV\n",
    "\n",
    "For the details of the implementation in `sklearn` we remind to the official page\n",
    "\n",
    "https://scikit-learn.org/0.16/modules/classes.html#module-sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's probably the simplest method and it work by dividing our entire dataset in a training and dataset. We train the model with the training data and we test the model on the test dataset. This method however has some ambiguity on how we choose and how big it has to be the two datasets. The implementation in `sklearn` reads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.cross_validation.train_test_split(*arrays, **options)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $k$-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, if we had enough data, we would set aside a validation set and use it to assess the performance of our prediction model. Since data are often scarce, this is usually not possible. To finesse the problem, $k$-fold cross-validation uses part of the available data to fit the model, and a different part to test it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/kfold.png\" style=\"max-width: 400px;margin:30px;\" />\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.cross_validation.KFold(n, n_folds=3, indices=None, shuffle=False, random_state=None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Repeated $k$-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeats $k$-Fold $n$ times with different randomization in each repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.model_selection.RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stratified  $k$-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It consists in $k$-fold iterator variant with non-overlapping groups. The same group will not appear in two different folds (the number of distinct groups has to be at least equal to the number of folds). The folds are approximately balanced in the sense that the number of distinct groups is approximately the same in each fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/strat.png\" style=\"max-width: 400px;margin:30px;\" />\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.model_selection.StratifiedKFold(n_splits=5, shuffle=False, random_state=None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leave-One-Out CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a $k$-fold CV with $k=n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/leave.png\" style=\"max-width: 400px;margin:30px;\" />\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.model_selection.LeaveOneOut`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leave-One-Group-Out CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Leave-One-Group-Out cross-validation method consists in performing a $k$-Fold CV in which the test subset contains a single group of the population studied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/group.png\" style=\"max-width: 400px;margin:30px;\" />\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.model_selection.LeaveOneGroupOut`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s4.2.3'></a>\n",
    "#### Other Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that a good model selection should have a small test error that in turn it depends on a good compromise between bias and variance. This tradeoff depends, in general, on the complexity of the model. Tuning the complexity of the model is related to other factors, like the __dimensionality__ of the input space, __Heterogeneity__ of the data, __Multi-collinearity__ that force the model to be more simple, using technique of regualarization. There are nevertheless other factors that can affect the test error and the selection and assestment of the model \n",
    "\n",
    "- __Noise in the output values__: An issue is the degree of noise in the desired output values . If the desired output values are often incorrect (because of human error or sensor errors), then the learning algorithm should not attempt to find a function that exactly matches the training examples. Attempting to fit the data too carefully leads to overfitting. You can overfit even when there are no measurement errors (stochastic noise) if the function you are trying to learn is too complex for your learning model. In such a situation, the part of the target function that cannot be modeled \"corrupts\" your training data this phenomenon has been called deterministic noise. When either type of noise is present, it is better to go with a higher bias, lower variance estimator.\n",
    "\n",
    "\n",
    "- __Redundancy in the data__: If the input features contain redundant information (e.g., highly correlated features), some learning algorithms (e.g., linear regression, logistic regression, and distance based methods) will perform poorly because of numerical instabilities. These problems can often be solved again by imposing some form of regularization\n",
    "\n",
    "\n",
    "- __Presence of interactions and non-linearities__: If each of the features makes an independent contribution to the output, then algorithms based on linear functions (linear regression, logistic regression, Support Vector Machines) and distance functions (nearest neighbor methods, support vector) generally perform well. However, if there are complex interactions among features, then algorithms such as decision trees and neural networks work better, because they are specifically designed to discover these interactions. Linear methods can also be applied, but the engineer must manually specify the interactions when using them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id='s5'>Interpretability</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before entering into the details of the methods used in machine learning problems to address the issue of __Intepretability__ we find useful to introduce the topic and give some terminology to avoid confusion due to ambiguity sometimes presents. \n",
    "\n",
    "First of all we recall the definition of algorithm. An __Algorithm__ is a set of rules that a machine follows to achieve a particular goal2. An algorithm can be considered as a recipe that defines the inputs, the output and all the steps needed to get from the inputs to the output.   A __Machine Learning Algorithm__ is the program used to learn a machine learning model from data. A __Machine Learning Model__ is the learned program that maps inputs to predictions. This can be a set of weights for a linear model or for a neural network. Other names for the rather unspecific word “model” are “predictor” or - depending on the task - “classifier” or “regression model”. It's what we usually call, in mathematical terms, $\\hat{f}$. \n",
    "\n",
    "A __Black Box Model__ is a system that does not reveal its internal mechanisms. In machine learning, “black box” describes models that cannot be understood by looking at their parameters (e.g. a neural network). The opposite of a black box is sometimes referred to as White Box, and is referred to in this book as interpretable model. \n",
    "\n",
    "__Interpretable Machine Learning__ refers to methods and models that make the behavior and predictions of machine learning systems understandable to humans.\n",
    "\n",
    "There is no mathematical definition of interpretability. A (non-mathematical) definition can be: Interpretability is the degree to which a human can understand the cause of a decision. Another one is: Interpretability is the degree to which a human can consistently predict the model’s result 4. The higher the interpretability of a machine learning model, the easier it is for someone to comprehend why certain decisions or predictions have been made. A model is better interpretable than another model if its decisions are easier for a human to comprehend than decisions from the other model.  \n",
    "\n",
    "If a machine learning model performs well, why do not we just trust the model and ignore why it made a certain decision? “The problem is that a single metric, such as classification accuracy, is an incomplete description of most real-world tasks.” Let us dive deeper into the reasons why interpretability is so important. When it comes to predictive modeling, you have to make a trade-off: Do you just want to know what is predicted? Or do you want to know why the prediction was made and possibly pay for the interpretability with a drop in predictive performance? In some cases, you do not care why a decision was made, it is enough to know that the predictive performance on a test dataset was good. But in other cases, knowing the ‘why’ can help you learn more about the problem, the data and the reason why a model might fail. Some models may not require explanations because they are used in a low-risk environment, meaning a mistake will not have serious consequences. The need for interpretability arises from an incompleteness in problem formalization (Doshi-Velez and Kim 2017), which means that for certain problems or tasks it is not enough to get the prediction. The model must also explain how it came to the prediction, because a correct prediction only partially solves your original problem. \n",
    "\n",
    "Essentially, Interpretability is just another layer on the model that helps humans to understand the process\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"images/inter.png\" style=\"max-width: 400px\" />\n",
    "</div> \n",
    "\n",
    "\n",
    "\n",
    "The following reasons drive the demand for interpretability and explanations\n",
    "\n",
    "- __Debugging__:\n",
    "\n",
    "    The world has a lot of unreliable, disorganized and generally dirty data. You add a potential source of errors as you write preprocessing code. Given the frequency and potentially disastrous consequences of bugs, debugging is one of the most valuable skills in data science. Understanding the patterns a model is finding will help you identify when those are at odds with your knowledge of the real world, and this is typically the first step in tracking down bugs. Interpretability is a useful debugging tool also for detecting bias in machine learning models.\n",
    "\n",
    "\n",
    "\n",
    "- __Directing Future Data Collection__:\n",
    "\n",
    "    You have no control over datasets you download online. But many businesses and organizations using data science have opportunities to expand what types of data they collect. Collecting new types of data can be expensive or inconvenient, so they only want to do this if they know it will be worthwhile. Model-based insights give you a good understanding of the value of features you currently have, which will help you reason about what new values may be most helpful.\n",
    "\n",
    "\n",
    "\n",
    "- __Informing Human Decision-Making__:\n",
    "\n",
    "    Some decisions are made automatically by models. Amazon doesn't have humans (or elves) scurry to decide what to show you whenever you go to their website. But many important decisions are made by humans. For these decisions, insights can be more valuable than predictions.\n",
    "\n",
    "\n",
    "\n",
    "- __Building Trust__:\n",
    "\n",
    "    Many people won't assume they can trust your model for important decisions without verifying some basic facts. This is a smart precaution given the frequency of data errors. In practice, showing insights that fit their general understanding of the problem will help build trust, even among people with little deep knowledge of data science.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method to implement Intepretability in machine learning usually fall into two categories : __Local__ and __Global__ methods. Each of them has a further classification into __Agnostic__ adn __Specific__ methods. \n",
    "\n",
    "To comprehend and interpret the whole model at once, we need __global__ interpretability. Global interpretability is all about being able to explain and understand model decisions based on conditional interactions between the dependent variables and the independent features on the complete dataset. Trying to understand feature interactions and importances is always a good step towards understanding global interpretation. Of course, visualizing features after more than two or three dimensions becomes quite difficult when trying to analyze interactions. Hence, often looking at modular parts and subsets of features, which might influence model predictions on a global knowledge, helps. Complete knowledge of the model structure, assumptions and constraints are needed for a global interpretation.\n",
    "\n",
    "\n",
    "For __local__ interpretability, we do not care about the inherent structure or assumptions of a model and we treat it as a black box. For understanding prediction decisions for a single datapoint, we focus specifically on that datapoint and look at a local subregion in our feature space around that point, and try to understand model decisions for that point based on this local region. Local data distributions and feature spaces might behave completely different and give more accurate explanations as opposed to global interpretations. We can use a combination of global and local interpretations to explain model decisions for a group of instances.\n",
    "\n",
    "\n",
    "Model-__specific__ interpretation tools are very specific to intrinsic model interpretation methods which depend purely on the capabilities and features on a per-model basis. This can be coefficients, p-values, AIC scores pertaining to a regression model, rules from a decision tree and so on. Model-__agnostic__ tools are more relevant and can be used on any machine learning model. These agnostic methods usually operate by analyzing feature input and output pairs. By definition, these methods do not have access to any model internals like weights, constraints or assumptions.\n",
    "\n",
    "We will focus on mainly on 3 methods: __Permutation Importance__, __Partial Dependece__ and __SHAP Values__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s5.1'></a>\n",
    "### Permutation Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most basic questions we might ask of a model is: What features have the biggest impact on predictions?\n",
    "\n",
    "This concept is called __feature importance__. There are multiple ways to measure feature importance. Here, we'll focus on __permutation importance__. Permutation importance is calculated after a model has been fitted. So we won't change the model or change what predictions we'd get for a given value of inputs.\n",
    "\n",
    "Instead we will ask the following question: If I randomly shuffle a single column of the validation data, leaving the target and all other columns in place, how would that affect the accuracy of predictions in that now-shuffled data?\n",
    "\n",
    "Permutation feature importance measures the increase in the prediction error of the model after we permuted the feature’s values, which breaks the relationship between the feature and the true outcome. The concept is really straightforward: We measure the importance of a feature by calculating the increase in the model’s prediction error after permuting the feature. A feature is “important” if shuffling its values increases the model error, because in this case the model relied on the feature for the prediction. A feature is “unimportant” if shuffling its values leaves the model error unchanged, because in this case the model ignored the feature for the prediction.\n",
    "\n",
    "With this insight, the process is as follows:\n",
    "\n",
    "1. Get a trained model.\n",
    "\n",
    "\n",
    "2. Shuffle the values in a single column, make predictions using the resulting dataset. Use these predictions and the true target values to calculate how much the loss function suffered from shuffling. That performance deterioration measures the importance of the variable you just shuffled.\n",
    "\n",
    "\n",
    "3. Return the data to the original order (undoing the shuffle from step 2). Now repeat step 2 with the next column in the dataset, until you have calculated the importance of each column.\n",
    "\n",
    "\n",
    "The implementation in python is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# Choosing the subset of features\n",
    "X = data[feature_names]\n",
    "y = data[target_name]\n",
    "\n",
    "# Train the model \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=1)\n",
    "my_model = DecisionTreeClassifier().fit(train_X, train_y)\n",
    "\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(test_X, test_y)\n",
    "eli5.show_weights(perm, feature_names = test_X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s5.2'></a>\n",
    "### Partial Dependence Plot (PDP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the most relevant variables have been identified, the next step is to attempt to understand the nature of the dependence of the approximation $\\hat{f}(X)$ on their joint values. Graphical renderings of the $f(X)$ as a function of its arguments provides a comprehensive summary of its dependence on the joint values of the input variables.\n",
    "\n",
    "The partial dependence plot is a global method: the method considers all instances and gives a statement about the global relationship of a feature with the predicted outcome.\n",
    "\n",
    "The Partial Dependence Plot (PDP) shows the marginal effect one or two features have on the predicted outcome of a machine learning model. A partial dependence plot can show whether the relationship between the target and a feature is linear, monotonic or more complex. For example, when applied to a linear regression model, partial dependence plots always show a linear relationship. \n",
    "\n",
    "The partial dependence function for regression is defined as:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}(x_{\\mathcal{S}})=E_{\\mathcal{C}}\\left[\\hat{f}\\left(x_{\\mathcal{S}}, x_{\\mathcal{C}}\\right)\\right]=\\int\\hat{f}\\left(x_{\\mathcal{S}}, x_{\\mathcal{C}}\\right)dP(x_{\\mathcal{C}})\n",
    "\\end{align}\n",
    "\n",
    "where $x_{\\mathcal{S}}$ are the input variable restricted to the subset of features $X_{\\mathcal{S}}$ and $x_{\\mathcal{C}}$ are the input variable restricted to the subset of features $X_{\\mathcal{C}}$ such that $X_{\\mathcal{S}}\\cup X_{\\mathcal{C}}=X_p$. \n",
    "\n",
    "Usually, there are only one or two features in the set $x_{\\mathcal{S}}$. The features in $x_{\\mathcal{S}}$ are those for which we want to know the effect on the prediction. Partial dependence works by marginalizing the machine learning model output over the distribution of the features in set $x_{\\mathcal{C}}$, so that the function shows the relationship between the features in set $x_{\\mathcal{S}}$ we are interested in and the predicted outcome. By marginalizing over the other features, we get a function that depends only on features in $x_{\\mathcal{S}}$, interactions with other features included.\n",
    "\n",
    "As usual, since we don't know the distribution law we estimate the dependence by:\n",
    "\n",
    "$\\quad$\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}(x_{\\mathcal{S}})=\\frac{1}{N}\\sum_{i}^N\\hat{f}\\left(x_{\\mathcal{S}}, x_{\\mathcal{C}}^i\\right)\n",
    "\\end{align}\n",
    "\n",
    "The partial function tells us for given values of features $x_{\\mathcal{S}}$ what the average marginal effect on the prediction is. An assumption of the PDP is that the features in  $\\mathcal{C}$  are not correlated with the features in $\\mathcal{S}$ . If this assumption is violated, the averages calculated for the partial dependence plot will include data points that are very unlikely or even impossible\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation in python use the `pdpbox` library in `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "# Choosing the subset of features\n",
    "X = data[feature_names]\n",
    "y = data[target_name]\n",
    "\n",
    "# Train the model \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=1)\n",
    "my_model = DecisionTreeClassifier().fit(train_X, train_y)\n",
    "\n",
    "\n",
    "# Create the data that we will plot\n",
    "pdp_goals = pdp.pdp_isolate(model=my_model, dataset=test_X, model_features=feature_names, feature='Goal Scored')\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(pdp_goals, 'Goal Scored')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example with 1 feature is shown below. The $y$ axis is interpreted as change in the prediction from what if would be predicted at the baseline of leftmost value. A blue shaded area indicates level of confidence. As we can see from the graph this model thinks we are more likely to win 'Player of the Game' if our players run a total of $100$km over the course of the game. Though running much more causes lower predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img width=500 src='images/pdp1.png' /> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example with a 2-dimensional feature space is shown below with a similar intepretation of the one above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img width=400 src='images/pdp2.png' /> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other example of these kind of plots. The complete list of methods using Partial Dependence and implemented in python can be found [here](https://pdpbox.readthedocs.io/en/latest/api.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s5.3'></a>\n",
    "### SHAP Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SHAP__ which stands for __SHapley Additive exPlanation__, it's a local method and it helps to break down a prediction to show the impact of each feature. It is based on __Shapley values__, a technique used in game theory to determine how much each player in a collaborative game has contributed to its success. Normally, getting the trade-off between accuracy and interpretability just right can be a difficult balancing act but SHAP values can deliver both. \n",
    "\n",
    "\n",
    "Since SHAP computes Shapley values, all the advantages of Shapley values apply: SHAP has a solid theoretical foundation in game theory. The prediction is fairly distributed among the feature values. We get contrastive explanations that compare the prediction with the average prediction.\n",
    "\n",
    "SHAP has a fast implementation for tree-based models. I believe this was key to the popularity of SHAP, because the biggest barrier for adoption of Shapley values is the slow computation.\n",
    "\n",
    "The fast computation makes it possible to compute the many Shapley values needed for the global model interpretations. The __global interpretation__ methods include __feature importance, feature dependence, interactions, clustering and summary plots__. With SHAP, global interpretations are consistent with the local explanations, since the Shapley values are the “atomic unit” of the global interpretations. \n",
    "\n",
    "\n",
    "We start therefore to introduce and explain what Shapley Values are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shapley Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prediction can be explained by assuming that each feature value of the instance is a “player” in a game where the prediction is the payout. Shapley values – a method from coalitional game theory – tells us how to fairly distribute the “payout” among the features.\n",
    "\n",
    "\n",
    "To better introduce the Shapley values, assume the following scenario:\n",
    "\n",
    "You have trained a machine learning model to predict apartment prices. For a certain apartment it predicts € 300,000 and you need to explain this prediction. The apartment has a _size_ of $50m^2$, is _located_ on the 2nd floor, has a _park nearby_ and cats are _banned_. \n",
    "The average prediction for all apartments is €310,000. How much has each feature value contributed to the prediction compared to the average prediction?\n",
    "\n",
    "The answer is simple for linear regression models. The effect of each feature is the weight of the feature times the feature value. This only works because of the linearity of the model. For more complex models, we need a different solution. This solution comes from cooperative game theory: The Shapley value, coined by Shapley (1953), is a method for assigning payouts to players depending on their contribution to the total payout. Players cooperate in a coalition and receive a certain profit from this cooperation. The “game” is the prediction task for a single instance of the dataset. The “gain” is the actual prediction for this instance minus the average prediction for all instances. The “players” are the feature values of the instance that collaborate to receive the gain.\n",
    "\n",
    "The Shapley value is the average marginal contribution of a feature value across all possible coalitions. In the example of the apartement The following list shows all coalitions of feature values that are needed to determine the Shapley value for _cat-banned_. The first row shows the coalition without any feature values. The second, third and fourth rows show different coalitions with increasing coalition size, separated by “|”. All in all, the following coalitions are possible:\n",
    "\n",
    "* No feature values\n",
    "* park-nearby\n",
    "* size-50\n",
    "* floor-2nd\n",
    "* park-nearby+size-50\n",
    "* park-nearby+floor-2nd\n",
    "* size-50+floor-2nd\n",
    "* park-nearby+size-50+floor-2nd\n",
    "\n",
    "\n",
    "For each of these coalitions we compute the predicted apartment price with and without the feature value cat-banned and take the difference to get the marginal contribution. The Shapley value is the (weighted) average of marginal contributions. We replace the feature values of features that are not in a coalition with random feature values from the apartment dataset to get a prediction from the machine learning model.\n",
    "\n",
    "For more details for the mathematical description of Shapley values we refer to https://christophm.github.io/interpretable-ml-book/shapley.html#the-shapley-value-in-detail\n",
    "\n",
    "The following figure shows SHAP explanation force plots:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img width=800 src='images/shap1.png' /> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SHAP Summary Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation importance is great because it created simple numeric measures to see which features mattered to a model. This helped us make comparisons between features easily, and you can present the resulting graphs to non-technical audiences.\n",
    "\n",
    "But it doesn't tell you how each features matter. If a feature has medium permutation importance, that could mean it has\n",
    "\n",
    "* a large effect for a few predictions, but no effect in general, or\n",
    "\n",
    "* a medium effect for all predictions.\n",
    "\n",
    "\n",
    "SHAP summary plots give us a birds-eye view of feature importance and what is driving it. We'll walk through an example plot for the soccer data. The code for the plot below reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(test_X)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values[1], test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img width=500 src='images/shap2.png' /> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is made of many dots. Each dot has three characteristics:\n",
    "\n",
    "* Vertical location shows what feature it is depicting\n",
    "\n",
    "\n",
    "* Color shows whether that feature was high or low for that row of the dataset\n",
    "\n",
    "\n",
    "* Horizontal location shows whether the effect of that value caused a higher or lower prediction.\n",
    "\n",
    "\n",
    "For example, the point in the upper left was for a team that scored few goals, reducing the prediction by 0.25.\n",
    "\n",
    "Some things you should be able to easily pick out:\n",
    "\n",
    "* The model ignored the Red and Yellow & Red features.\n",
    "\n",
    "\n",
    "* Usually Yellow Card doesn't affect the prediction, but there is an extreme case where a high value caused a much lower prediction.\n",
    "\n",
    "\n",
    "* High values of Goal scored caused higher predictions, and low values caused low predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SHAP Dependence Contribution Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've previously used Partial Dependence Plots to show how a single feature impacts predictions. These are insightful and relevant for many real-world use cases. Plus, with a little effort, they can be explained to a non-technical audience.\n",
    "\n",
    "But there's a lot they don't show. For instance, what is the distribution of effects? Is the effect of having a certain value pretty constant, or does it vary a lot depending on the values of other feaures. SHAP dependence contribution plots provide a similar insight to PDP's, but they add a lot more detail.\n",
    "\n",
    "The code giving the plot below reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# make plot.\n",
    "shap.dependence_plot('Ball Possession %', shap_values[1], X, interaction_index=\"Goal Scored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img width=500 src='images/shap3.png' /> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by focusing on the shape, and we'll come back to color in a minute. Each dot represents a row of the data. The horizontal location is the actual value from the dataset, and the vertical location shows what having that value did to the prediction. The fact this slopes upward says that the more you possess the ball, the higher the model's prediction is for winning the Man of the Match award.\n",
    "\n",
    "The spread suggests that other features must interact with Ball Possession %. For example, here we have highlighted two points with similar ball possession values. That value caused one prediction to increase, and it caused the other prediction to decrease.\n",
    "\n",
    "For comparison, a simple linear regression would produce plots that are perfect lines, without this spread.\n",
    "\n",
    "This suggests we delve into the interactions, and the plots include color coding to help do that. While the primary trend is upward, you can visually inspect whether that varies by dot color.\n",
    "\n",
    "For example the two points and the right bottom of the picture above stand out spatially as being far away from the upward trend. They are both colored purple, indicating the team scored one goal. You can interpret this to say In general, having the ball increases a team's chance of having their player win the award. But if they only score one goal, that trend reverses and the award judges may penalize them for having the ball so much if they score that little."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
